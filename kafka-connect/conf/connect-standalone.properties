group.id=kafka-connect-splunk-hec-sink

bootstrap.servers=broker:29092

key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.storage.StringConverter

key.converter.schemas.enable=false
value.converter.schemas.enable=false

# internal.key.converter=org.apache.kafka.connect.json.JsonConverter
# internal.value.converter=org.apache.kafka.connect.json.JsonConverter

# internal.key.converter.schemas.enable=false
# internal.value.converter.schemas.enable=false

# Flush much faster (10s) than normal, which is useful for testing/debugging
offset.flush.interval.ms=10000

config.storage.topic=__kafka-connect-splunk-task-configs
config.storage.replication.factor=1

offset.storage.topic=__kafka-connect-splunk-offsets
offset.storage.replication.factor=1
offset.storage.partitions=5
offset.storage.file.filename=/tmp/connect.offsets

status.storage.topic=__kafka-connect-splunk-statuses
status.storage.replication.factor=1
status.storage.partitions=5

# offset.storage.topic=docker-connect-offsets
# offset.storage.replication.factor=1

# plugin.path=/usr/share/java,/usr/share/confluent-hub-components,/etc/kafka-connect/jars
plugin.path=/usr/share/java,/etc/kafka-connect/jars

#rest.advertised.host.name=connect
# rest.advertised.host.name=localhost
#rest.port=8083

# Confluent interceptors
# producer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
# consumer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
